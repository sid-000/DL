{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "o2nkj4ZhJtAO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, Dropout,BatchNormalization,GlobalAveragePooling2D\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! git config --global --unset https.proxy\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "import time\n",
        "import imageio.v3 as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "\n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])\n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(nd.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data).astype('float32') / 255.0, np.array(train_labels), np.array(test_data).astype('float32') / 255.0, np.array(test_labels)\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_images.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_images.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.05, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85tQIrs5JzdU",
        "outputId": "601f1794-43bd-4eee-e338-11d1b03aa7f0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'IMagenet' already exists and is not an empty directory.\n",
            "test  train  val  wnids.txt  words.txt\n",
            "starting loading data\n",
            "finished loading data, in 44.53892779350281 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model('/content/model_configuration3.h5')\n",
        "\n",
        "# Check its architecture\n",
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze60u7U5oE59",
        "outputId": "259a46f9-36f8-47b4-b400-febd058c39cf"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227146 (887.29 KB)\n",
            "Trainable params: 227146 (887.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.pop()"
      ],
      "metadata": {
        "id": "yp77T1booSYY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False"
      ],
      "metadata": {
        "id": "O9RCZQW-oSU_"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxvW2wgqoSSg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), input_shape=(64, 64, 3)))\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(.25))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(200, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy (base model on TinyImagenet): {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON0p1TXaJzgB",
        "outputId": "e6ba39cb-4ac9-4f9f-ca5a-c5d0d866dc5d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1336/1336 [==============================] - 10s 6ms/step - loss: 5.0911 - categorical_accuracy: 0.0223 - val_loss: 4.9447 - val_categorical_accuracy: 0.0339\n",
            "Epoch 2/5\n",
            "1336/1336 [==============================] - 7s 5ms/step - loss: 4.9680 - categorical_accuracy: 0.0312 - val_loss: 4.8988 - val_categorical_accuracy: 0.0387\n",
            "Epoch 3/5\n",
            "1336/1336 [==============================] - 7s 5ms/step - loss: 4.9335 - categorical_accuracy: 0.0348 - val_loss: 4.8835 - val_categorical_accuracy: 0.0396\n",
            "Epoch 4/5\n",
            "1336/1336 [==============================] - 7s 5ms/step - loss: 4.9128 - categorical_accuracy: 0.0358 - val_loss: 4.8793 - val_categorical_accuracy: 0.0420\n",
            "Epoch 5/5\n",
            "1336/1336 [==============================] - 7s 5ms/step - loss: 4.8992 - categorical_accuracy: 0.0380 - val_loss: 4.8646 - val_categorical_accuracy: 0.0418\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 4.8866 - categorical_accuracy: 0.0376\n",
            "Test Accuracy (base model on TinyImagenet): 3.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('base_model_tiny_image.h5')"
      ],
      "metadata": {
        "id": "7NY0xNwyJzig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3a7172c-6dc3-4b58-8a34-c955d6075e75"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cviohs0qJzlJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLhMbv-HJzo_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X50eU2XrnEbr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d5FMvvC0JzsX"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}
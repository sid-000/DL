{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o2nkj4ZhJtAO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, Dropout,BatchNormalization,GlobalAveragePooling2D\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! git config --global --unset https.proxy\n",
        "! git clone https://github.com/seshuad/IMagenet\n",
        "! ls 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "import time\n",
        "import imageio.v3 as nd\n",
        "import numpy as np\n",
        "\n",
        "path = 'IMagenet/tiny-imagenet-200/'\n",
        "\n",
        "def get_id_dictionary():\n",
        "    id_dict = {}\n",
        "    for i, line in enumerate(open( path + 'wnids.txt', 'r')):\n",
        "        id_dict[line.replace('\\n', '')] = i\n",
        "    return id_dict\n",
        "\n",
        "def get_class_to_id_dict():\n",
        "    id_dict = get_id_dictionary()\n",
        "    all_classes = {}\n",
        "    result = {}\n",
        "    for i, line in enumerate(open( path + 'words.txt', 'r')):\n",
        "        n_id, word = line.split('\\t')[:2]\n",
        "        all_classes[n_id] = word\n",
        "    for key, value in id_dict.items():\n",
        "        result[value] = (key, all_classes[key])\n",
        "    return result\n",
        "\n",
        "def get_data(id_dict):\n",
        "    print('starting loading data')\n",
        "    train_data, test_data = [], []\n",
        "    train_labels, test_labels = [], []\n",
        "    t = time.time()\n",
        "    for key, value in id_dict.items():\n",
        "        train_data += [nd.imread( path + 'train/{}/images/{}_{}.JPEG'.format(key, key, str(i)), mode='RGB') for i in range(500)]\n",
        "        train_labels_ = np.array([[0]*200]*500)\n",
        "        train_labels_[:, value] = 1\n",
        "        train_labels += train_labels_.tolist()\n",
        "\n",
        "    for line in open( path + 'val/val_annotations.txt'):\n",
        "        img_name, class_id = line.split('\\t')[:2]\n",
        "        test_data.append(nd.imread( path + 'val/images/{}'.format(img_name) ,mode='RGB'))\n",
        "        test_labels_ = np.array([[0]*200])\n",
        "        test_labels_[0, id_dict[class_id]] = 1\n",
        "        test_labels += test_labels_.tolist()\n",
        "\n",
        "    print('finished loading data, in {} seconds'.format(time.time() - t))\n",
        "    return np.array(train_data).astype('float32') / 255.0, np.array(train_labels), np.array(test_data).astype('float32') / 255.0, np.array(test_labels)\n",
        "\n",
        "train_images, train_labels, test_images, test_labels = get_data(get_id_dictionary())\n",
        "\n",
        "print( \"train data shape: \",  train_images.shape )\n",
        "print( \"train label shape: \", train_labels.shape )\n",
        "print( \"test data shape: \",   test_images.shape )\n",
        "print( \"test_labels.shape: \", test_labels.shape )\n",
        "\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(train_images, train_labels, test_size=0.05, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85tQIrs5JzdU",
        "outputId": "a54ab64c-4062-4534-aeda-90a583ebbe08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IMagenet'...\n",
            "remote: Enumerating objects: 120594, done.\u001b[K\n",
            "remote: Total 120594 (delta 0), reused 0 (delta 0), pack-reused 120594\u001b[K\n",
            "Receiving objects: 100% (120594/120594), 212.68 MiB | 39.73 MiB/s, done.\n",
            "Resolving deltas: 100% (1115/1115), done.\n",
            "Updating files: 100% (120206/120206), done.\n",
            "test  train  val  wnids.txt  words.txt\n",
            "starting loading data\n",
            "finished loading data, in 46.55139660835266 seconds\n",
            "train data shape:  (100000, 64, 64, 3)\n",
            "train label shape:  (100000, 200)\n",
            "test data shape:  (10000, 64, 64, 3)\n",
            "test_labels.shape:  (10000, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model('/content/model_configuration3.h5')\n",
        "\n",
        "# Check its architecture\n",
        "base_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze60u7U5oE59",
        "outputId": "9c538d40-af5a-406d-e281-8bc7cff785fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227146 (887.29 KB)\n",
            "Trainable params: 227146 (887.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.pop()"
      ],
      "metadata": {
        "id": "yp77T1booSYY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False"
      ],
      "metadata": {
        "id": "O9RCZQW-oSU_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GxvW2wgqoSSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), input_shape=(64, 64, 3)))\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(.25))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(200, activation='softmax'))\n",
        "\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy (base model on TinyImagenet): {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON0p1TXaJzgB",
        "outputId": "75eac12c-b2f1-4336-c1ad-f6e08ad80c11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1336/1336 [==============================] - 16s 8ms/step - loss: 5.0985 - categorical_accuracy: 0.0221 - val_loss: 4.9346 - val_categorical_accuracy: 0.0344\n",
            "Epoch 2/5\n",
            "1336/1336 [==============================] - 9s 7ms/step - loss: 4.9729 - categorical_accuracy: 0.0304 - val_loss: 4.8925 - val_categorical_accuracy: 0.0411\n",
            "Epoch 3/5\n",
            "1336/1336 [==============================] - 9s 7ms/step - loss: 4.9369 - categorical_accuracy: 0.0339 - val_loss: 4.8808 - val_categorical_accuracy: 0.0402\n",
            "Epoch 4/5\n",
            "1336/1336 [==============================] - 9s 7ms/step - loss: 4.9144 - categorical_accuracy: 0.0352 - val_loss: 4.8699 - val_categorical_accuracy: 0.0398\n",
            "Epoch 5/5\n",
            "1336/1336 [==============================] - 9s 7ms/step - loss: 4.9042 - categorical_accuracy: 0.0365 - val_loss: 4.8644 - val_categorical_accuracy: 0.0417\n",
            "157/157 [==============================] - 1s 4ms/step - loss: 4.8894 - categorical_accuracy: 0.0404\n",
            "Test Accuracy (base model on TinyImagenet): 4.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('custom_model_tiny_image.h5')"
      ],
      "metadata": {
        "id": "7NY0xNwyJzig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dee2b5f-92dc-4ef9-8fbe-b83eb46763ef"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.models.load_model('/content/model_configuration3.h5')"
      ],
      "metadata": {
        "id": "Cviohs0qJzlJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "sLhMbv-HJzo_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "421f1ea0-3008-46d9-b806-85559b181a93"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 227146 (887.29 KB)\n",
            "Trainable params: 227146 (887.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.pop()"
      ],
      "metadata": {
        "id": "h-J6qNMQwWBT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X50eU2XrnEbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finetunning of the base_model can improve the accuracy.\n",
        "base_model.trainable=True"
      ],
      "metadata": {
        "id": "d5FMvvC0JzsX"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), input_shape=(64, 64, 3)))\n",
        "model.add(base_model)\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(.25))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(200, activation='softmax'))"
      ],
      "metadata": {
        "id": "2p9ZuStbzEy4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
        "\n",
        "history = model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test Accuracy (base model on TinyImagenet): {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtzDP5HgwUJp",
        "outputId": "3c0b3f27-82cd-4065-b8b2-99312f4de5be"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1336/1336 [==============================] - 13s 7ms/step - loss: 4.9971 - categorical_accuracy: 0.0271 - val_loss: 4.7298 - val_categorical_accuracy: 0.0502\n",
            "Epoch 2/5\n",
            "1336/1336 [==============================] - 9s 7ms/step - loss: 4.6245 - categorical_accuracy: 0.0585 - val_loss: 4.5355 - val_categorical_accuracy: 0.0704\n",
            "Epoch 3/5\n",
            "1336/1336 [==============================] - 9s 6ms/step - loss: 4.4438 - categorical_accuracy: 0.0755 - val_loss: 4.3552 - val_categorical_accuracy: 0.0940\n",
            "Epoch 4/5\n",
            "1336/1336 [==============================] - 9s 6ms/step - loss: 4.3244 - categorical_accuracy: 0.0918 - val_loss: 4.3223 - val_categorical_accuracy: 0.0965\n",
            "Epoch 5/5\n",
            "1336/1336 [==============================] - 9s 6ms/step - loss: 4.2398 - categorical_accuracy: 0.1024 - val_loss: 4.2652 - val_categorical_accuracy: 0.1053\n",
            "157/157 [==============================] - 0s 3ms/step - loss: 4.2790 - categorical_accuracy: 0.1068\n",
            "Test Accuracy (base model on TinyImagenet): 10.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('custom_funetunning.h5')"
      ],
      "metadata": {
        "id": "Zn4sRhnRwUOU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lAkvPAXpwUSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shs2NhEtwUWT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}